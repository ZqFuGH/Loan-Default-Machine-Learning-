{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9defaa42",
   "metadata": {},
   "source": [
    "# Big Data in Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ddac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import threadpoolctl\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "df_sf=pd.read_csv(\"/Users/chorkid/Desktop/Imperial/Modules/2024 Spring/Big Data/Coursework/sfdata.csv\")\n",
    "df_sf.drop(columns=df_sf.columns[0:1], inplace=True)\n",
    "df_sf.set_index('LOAN_ID', drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697f1eb",
   "metadata": {},
   "source": [
    "## Data Cleaning and Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e60080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop columns after manual selection\n",
    "column_string='PPMT_FLG, IO, PRODUCT, SERVICER, MASTER_SERVICER, ISSUANCE_UPB, CURRENT_UPB, LOAN_AGE, REM_MONTHS, ADJ_REM_MONTHS, MATR_DT, CSCORE_C, ZIP, FIRST_PAY_IO, MNTHS_TO_AMTZ_IO, DLQ_STATUS, PMT_HISTORY, MOD_FLAG, MI_CANCEL_FLAG, RPRCH_DTE, CURR_SCHD_PRNCPL, TOT_SCHD_PRNCPL, UNSCHD_PRNCPL_CURR, LAST_PAID_INSTALLMENT_DATE, FORECLOSURE_DATE, DISPOSITION_DATE, ASSET_RECOVERY_COSTS, ORIGINAL_LIST_START_DATE, ORIGINAL_LIST_PRICE, CURRENT_LIST_START_DATE, CURRENT_LIST_PRICE, SERV_IND, CURRENT_PERIOD_MODIFICATION_LOSS_AMOUNT, CUMULATIVE_MODIFICATION_LOSS_AMOUNT, CURRENT_PERIOD_CREDIT_EVENT_NET_GAIN_OR_LOSS, CUMULATIVE_CREDIT_EVENT_NET_GAIN_OR_LOSS, FORECLOSURE_PRINCIPAL_WRITE_OFF_AMOUNT, ZERO_BALANCE_CODE_CHANGE_DATE, LOAN_HOLDBACK_INDICATOR, LOAN_HOLDBACK_EFFECTIVE_DATE, DELINQUENT_ACCRUED_INTEREST, ARM_5_YR_INDICATOR, ARM_PRODUCT_TYPE, MONTHS_UNTIL_FIRST_PAYMENT_RESET, MONTHS_BETWEEN_SUBSEQUENT_PAYMENT_RESET, INTEREST_RATE_CHANGE_DATE, PAYMENT_CHANGE_DATE, ARM_INDEX, ARM_CAP_STRUCTURE, INITIAL_INTEREST_RATE_CAP, PERIODIC_INTEREST_RATE_CAP, LIFETIME_INTEREST_RATE_CAP, MARGIN, BALLOON_INDICATOR, PLAN_NUMBER, DEAL_NAME'\n",
    "list_col_delete=column_string.split(\", \")\n",
    "df_sf=df_sf.drop(list_col_delete,axis=1)\n",
    "\n",
    "## convert datetime to be numerical (set earliest date be 1, if one day later, then add 1)\n",
    "df_sf['ACT_PERIOD'] = pd.to_datetime(df_sf['ACT_PERIOD'])\n",
    "df_sf['ORIG_DATE'] = pd.to_datetime(df_sf['ORIG_DATE'])\n",
    "df_sf['FIRST_PAY'] = pd.to_datetime(df_sf['FIRST_PAY'])\n",
    "df_sd_min_date=df_sf[['ACT_PERIOD','ORIG_DATE','FIRST_PAY']].min().min()\n",
    "df_sf['ACT_PERIOD'] = (df_sf['ACT_PERIOD'] - df_sd_min_date).dt.days+1\n",
    "df_sf['ORIG_DATE'] = (df_sf['ORIG_DATE'] - df_sd_min_date).dt.days+1\n",
    "df_sf['FIRST_PAY'] = (df_sf['FIRST_PAY'] - df_sd_min_date).dt.days+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dde4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with NaN\n",
    "df_sf['CURR_RATE'] = df_sf['CURR_RATE'].fillna(df_sf['ORIG_RATE'])\n",
    "df_sf['NUM_BO']=df_sf['NUM_BO'].apply(lambda x: 1 if x > 1 else 0)\n",
    "df_sf['CSCORE_B']=df_sf['CSCORE_B'].fillna(df_sf['CSCORE_B'].median()).round()\n",
    "df_sf['HOMEREADY_PROGRAM_INDICATOR']=df_sf['FORBEARANCE_INDICATOR'].apply(lambda x: '7' if x == 7 else x)\n",
    "df_sf[\"MI_PCT\"]=df_sf['MI_PCT'].fillna(0).astype(float)\n",
    "df_sf[['FORECLOSURE_COSTS','PROPERTY_PRESERVATION_AND_REPAIR_COSTS','MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS',\n",
    "       'ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY','NET_SALES_PROCEEDS','CREDIT_ENHANCEMENT_PROCEEDS',\n",
    "       'REPURCHASES_MAKE_WHOLE_PROCEEDS','OTHER_FORECLOSURE_PROCEEDS','NON_INTEREST_BEARING_UPB',\n",
    "       'PRINCIPAL_FORGIVENESS_AMOUNT']]=df_sf[['FORECLOSURE_COSTS','PROPERTY_PRESERVATION_AND_REPAIR_COSTS',\n",
    "                                               'MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS',\n",
    "                                               'ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY','NET_SALES_PROCEEDS',\n",
    "                                               'CREDIT_ENHANCEMENT_PROCEEDS','REPURCHASES_MAKE_WHOLE_PROCEEDS',\n",
    "                                               'OTHER_FORECLOSURE_PROCEEDS','NON_INTEREST_BEARING_UPB',\n",
    "                                               'PRINCIPAL_FORGIVENESS_AMOUNT']].fillna(0)\n",
    "df_sf['MI_TYPE']=df_sf['MI_TYPE'].fillna(0)\n",
    "df_sf['MI_TYPE']=df_sf['MI_TYPE'].astype(str)\n",
    "\n",
    "df_sf['FORBEARANCE_INDICATOR']=df_sf['FORBEARANCE_INDICATOR'].fillna('0')\n",
    "df_sf['FORBEARANCE_INDICATOR']=df_sf['FORBEARANCE_INDICATOR'].apply(lambda x: '7' if x == 7 or x==7.0 else x)\n",
    "df_sf['ADR_TYPE']=df_sf['ADR_TYPE'].fillna('0')\n",
    "df_sf['ADR_TYPE']=df_sf['ADR_TYPE'].apply(lambda x: '7' if x == 7 or x==7.0 else x)\n",
    "df_sf['PROPERTY_INSPECTION_WAIVER_INDICATOR']=df_sf['PROPERTY_INSPECTION_WAIVER_INDICATOR'].fillna('0')\n",
    "df_sf['HOMEREADY_PROGRAM_INDICATOR']=df_sf['HOMEREADY_PROGRAM_INDICATOR'].fillna('0')\n",
    "\n",
    "## drop rows with NaN in column DTI and LAST_UPB\n",
    "df_sf.dropna(subset=['DTI','LAST_UPB',],inplace=True)\n",
    "\n",
    "## drop columns with more than 98% NaN\n",
    "df_sf.dropna(thresh=round(len(df_sf)/50), axis=1,inplace=True)\n",
    "\n",
    "# check if there is still NaN in the dataframe\n",
    "#df_sf.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202156e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS OF DATA\n",
    "df_sf_copy=df_sf.copy()\n",
    "\n",
    "## divide original dataframe into defaulted and non-defaulted dataframe\n",
    "df_sf_non_default=df_sf_copy[df_sf_copy['loan_status']=='Fully Repaid']\n",
    "df_sf_default=df_sf_copy[df_sf_copy['loan_status']=='Defaulted']\n",
    "df_sf_non_default.dropna(thresh=round(len(df_sf_non_default)/50), axis=1,inplace=True)\n",
    "df_sf_default.dropna(thresh=round(len(df_sf_default)/50), axis=1,inplace=True)\n",
    "## difference of variables between two dataframes, and defaulted contains all variables in non-defaulted\n",
    "diff_def_nondef = set(df_sf_non_default.columns).symmetric_difference(set(df_sf_default.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert all numerical data to be float datatype\n",
    "df_sf[numerical_cols]=df_sf[numerical_cols].astype(float)\n",
    "## convert categorical data\n",
    "df_sf['MSA']=df_sf['MSA'].astype(str)\n",
    "df_sf['Zero_Bal_Code']=df_sf['Zero_Bal_Code'].astype(str)\n",
    "\n",
    "# identify and convert dummy variables \n",
    "num_unique_values = df_sf.nunique()\n",
    "\n",
    "## filter columns where the number of unique values is 2\n",
    "binary_cols = num_unique_values[num_unique_values == 2].index\n",
    "binary_cols = binary_cols[:-1]\n",
    "\n",
    "## get the number of unique values in each of these binary columns\n",
    "num_unique_binary_values = df_sf[binary_cols].nunique()\n",
    "\n",
    "## create dummy variables for binary columns\n",
    "dummy_df = pd.get_dummies(df_sf[binary_cols], drop_first=True)\n",
    "\n",
    "## drop the original binary columns\n",
    "df_sf_dummies = pd.concat([df_sf, dummy_df], axis=1)\n",
    "df_sf_dummies.drop(columns=binary_cols, inplace=True)\n",
    "\n",
    "## save categorical dataframe and numerical dataframe respectively\n",
    "### numerical\n",
    "numerical_cols = df_sf_copy.select_dtypes(include=['number']).columns\n",
    "df_sf_num=df_sf_copy[numerical_cols]\n",
    "### categorical\n",
    "categorical_cols = df_sf_copy.select_dtypes(include=['category', 'object', 'bool']).columns\n",
    "df_sf_cat=df_sf_copy[categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03849cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation\n",
    "df_sf_num_corr=df_sf_num.corr()\n",
    "\n",
    "## drop high correlated variables\n",
    "df_sf = df_sf.drop({'FORECLOSURE_COSTS','PROPERTY_PRESERVATION_AND_REPAIR_COSTS','MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS', 'ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY','NET_SALES_PROCEEDS','CREDIT_ENHANCEMENT_PROCEEDS', 'REPURCHASES_MAKE_WHOLE_PROCEEDS', 'OTHER_FORECLOSURE_PROCEEDS','Zero_Bal_Code'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121c303",
   "metadata": {},
   "source": [
    "## Sampling and Rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c82a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide train and test set\n",
    "df_sf_train, df_sf_test = train_test_split(df_sf, test_size=0.3)\n",
    "\n",
    "# balancing data\n",
    "\n",
    "## reduce the numder of Fully Repaid data randomly\n",
    "### divide two unbalancing data set\n",
    "df_sf_train_fully_repaid=df_sf_train[df_sf_train['loan_status']=='Fully Repaid']\n",
    "df_sf_train_default=df_sf_train[df_sf_train['loan_status']=='Defaulted']\n",
    "\n",
    "### select 600000 data\n",
    "df_sf_reduced_fully_repaid=df_sf_train_fully_repaid.sample(n=300000)\n",
    "df_sf_train = pd.concat([df_sf_reduced_fully_repaid, df_sf_train_default], axis=0, ignore_index=True)\n",
    "\n",
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "df_sf_train[numerical_cols] = scaler.fit_transform(df_sf_train[numerical_cols])\n",
    "df_sf_test[numerical_cols] = scaler.transform(df_sf_test[numerical_cols])\n",
    "\n",
    "## use SMOTE to oversampling Defaulted data\n",
    "x_train=df_sf_train.drop(columns=['loan_status'])\n",
    "y_train=df_sf_train['loan_status']\n",
    "x_test=df_sf_test.drop(columns=['loan_status'])\n",
    "y_test=df_sf_test['loan_status']\n",
    "\n",
    "### oversampling for defaulted data\n",
    "categorical_cols = x_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "categorical_cols_index = [x_train.columns.get_loc(name) for name in categorical_cols]\n",
    "smotenc =SMOTENC(categorical_features=categorical_cols_index, random_state=42)\n",
    "x_res_train,y_res_train=smotenc.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95f478",
   "metadata": {},
   "source": [
    "## Tree-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f62162",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec138947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot-encode each independent category as a binary variable using 0 or 1, didn't change y\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "## encode test data\n",
    "ohe = OneHotEncoder(dtype=\"int\")\n",
    "ohe.fit(df_sf_test[categorical_cols])\n",
    "df_sf_test_ohe = ohe.transform(df_sf_test[categorical_cols]).toarray()\n",
    "\n",
    "transformed_ohe = pd.DataFrame(\n",
    "    data=df_sf_test_ohe,\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=df_sf_test.index,\n",
    ")\n",
    "ds1 = transformed_ohe \n",
    "transformed_ohe = transformed_ohe.drop({'MSA_13220', 'SELLER_Home Point Mortgage Acceptance Corporation', 'SELLER_Fbc Mortgage Llc', 'MSA_27060', 'MSA_25980', 'MSA_27780', 'MSA_10380', 'SELLER_Peoples Home Equity, Inc.', 'MSA_21820', 'MSA_21420', 'SELLER_Prospect Mortgage, Llc', 'HOMEREADY_PROGRAM_INDICATOR_N', 'MSA_11640', 'MSA_21300', 'MSA_48260', 'SELLER_CrossCountry Mortgage, LLC', 'MSA_44940', 'FORBEARANCE_INDICATOR_N', 'MSA_38220', 'MSA_42700', 'PROPERTY_INSPECTION_WAIVER_INDICATOR_R', 'MSA_25020', 'MSA_41900', 'STATE_GU', 'MSA_11020', 'SELLER_Guild Mortgage Company LLC'},axis=1)\n",
    "\n",
    "### merge dataframes\n",
    "df_sf_test_encoded = pd.concat([df_sf_test.drop(categorical_cols,axis=1), transformed_ohe], axis=1)\n",
    "\n",
    "x_res_test_encoded = df_sf_test_encoded.drop(\"loan_status\", axis=1)\n",
    "y_res_test = df_sf_test[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode training data\n",
    "ohe = OneHotEncoder(dtype=\"int\")\n",
    "ohe.fit(x_res_train[categorical_cols])\n",
    "x_res_train_ohe = ohe.transform(x_res_train[categorical_cols]).toarray()\n",
    "\n",
    "\n",
    "transformed_ohe = pd.DataFrame(\n",
    "    data=x_res_train_ohe,\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=x_res_train,\n",
    ")\n",
    "ds2 = transformed_ohe\n",
    "\n",
    "## reset indices of the DataFrames\n",
    "x_res_train.reset_index(drop=True, inplace=True)\n",
    "transformed_ohe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# concatenate the DataFrames\n",
    "x_res_train_encoded = pd.concat([x_res_train.drop(categorical_cols, axis=1), transformed_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98701789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of columns from each dataset\n",
    "columns_df1 = set(ds1)\n",
    "columns_df2 = set(ds2)\n",
    "\n",
    "# find the columns that are present in one dataset but not in the other\n",
    "columns_only_in_df1 = columns_df1 - columns_df2\n",
    "columns_only_in_df2 = columns_df2 - columns_df1\n",
    "\n",
    "# print the differences for elimination\n",
    "print(\"Columns only in ds1:\", columns_only_in_df1)\n",
    "print(\"Columns only in ds2\", columns_only_in_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d588578",
   "metadata": {},
   "source": [
    "### Basic decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57db07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree model with hyperparameters search\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30, 35],\n",
    "    'min_samples_split': [10, 20, 50, 100],\n",
    "    'min_samples_leaf': [3, 5, 10, 20],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# perform grid search cross-validation\n",
    "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5)\n",
    "grid_search.fit(x_res_train_encoded, y_res_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec951c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the decision tree model with the best hyperparameters\n",
    "best_tree = grid_search.best_estimator_\n",
    "y_pred_dt = best_tree.predict(x_res_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_tree, filled=True, feature_names=x_res_train_encoded.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623102bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = accuracy_score(y_res_test, y_pred_dt)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "class_names = ['Defaulted', 'Fully Repaid']\n",
    "disp_tree = ConfusionMatrixDisplay.from_estimator(\n",
    "        best_tree,\n",
    "        x_res_test_encoded,\n",
    "        y_res_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b799d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test_encoded=y_res_test.replace({'Defaulted': 1, 'Fully Repaid': 0})\n",
    "y_pred_dt_encoded = best_tree.predict_proba(x_res_test_encoded)[:, 0]\n",
    "\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test_encoded, y_pred_dt_encoded)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_dt, tpr_dt, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc_dt)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a68185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "feature_importances = best_tree.feature_importances_\n",
    "feature_names = x_res_train_encoded.columns \n",
    "\n",
    "# sort the feature importances in descending order\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "sorted_importances = feature_importances[sorted_indices]\n",
    "sorted_feature_names = feature_names[sorted_indices]\n",
    "\n",
    "# select the top 5 features\n",
    "top_n = 10\n",
    "top_indices = sorted_indices[:top_n]\n",
    "top_importances = sorted_importances[:top_n]\n",
    "top_feature_names = sorted_feature_names[:top_n]\n",
    "\n",
    "# plot the top 5 feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_importances)), top_importances, tick_label=top_feature_names)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9d5ca",
   "metadata": {},
   "source": [
    "### Gradient Boosting Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train boosted tree\n",
    "GDC_tree = GradientBoostingClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'n_estimators': [5, 10, 30, 100], \n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'subsample': [0.1, 0.3, 0.5],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=GDC_tree, param_grid=param_grid, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_res_train_encoded, y_res_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score: \", grid_search.best_score_)\n",
    "\n",
    "# fit boosted tree\n",
    "best_boosted = grid_search.best_estimator_\n",
    "y_pred_boosted = best_boosted.predict(x_res_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = accuracy_score(y_res_test, y_pred_boosted)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "class_names = ['Defaulted', 'Fully Repaid']\n",
    "disp_boosted = ConfusionMatrixDisplay.from_estimator(\n",
    "        best_boosted,\n",
    "        x_res_test_encoded,\n",
    "        y_res_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test_encoded=y_res_test.replace({'Defaulted': 1, 'Fully Repaid': 0})\n",
    "# predict_prob\n",
    "y_pred_boosted_encoded = best_boosted.predict_proba(x_res_test_encoded)[:, 0]\n",
    "\n",
    "fpr_boosted, tpr_boosted, thresholds_boosted = roc_curve(y_test_encoded, y_pred_boosted_encoded)\n",
    "\n",
    "# compute the area under the ROC curve (AUC)\n",
    "roc_auc_boosted = auc(fpr_boosted, tpr_boosted)\n",
    "\n",
    "# plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_boosted, tpr_boosted, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc_boosted)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c674bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "feature_importances = best_boosted.feature_importances_\n",
    "feature_names = x_res_train_encoded.columns  \n",
    "\n",
    "# sort the feature importances in descending order\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "sorted_importances = feature_importances[sorted_indices]\n",
    "sorted_feature_names = feature_names[sorted_indices]\n",
    "\n",
    "# select the top 5 features\n",
    "top_n = 10\n",
    "top_indices = sorted_indices[:top_n]\n",
    "top_importances = sorted_importances[:top_n]\n",
    "top_feature_names = sorted_feature_names[:top_n]\n",
    "\n",
    "# plot the top 5 feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_importances)), top_importances, tick_label=top_feature_names)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444cb47",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561aaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train random forest\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 30], \n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_leaf': [100, 200, 300, 400],\n",
    "    'min_samples_split': [200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, return_train_score=True)\n",
    "grid_search.fit(x_res_train_encoded, y_res_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score: \", grid_search.best_score_)\n",
    "\n",
    "# fit random forest\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(x_res_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = accuracy_score(y_res_test, y_pred_rf)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "class_names = ['Defaulted', 'Fully Repaid']\n",
    "disp_rf = ConfusionMatrixDisplay.from_estimator(\n",
    "        best_rf,\n",
    "        x_res_test_encoded,\n",
    "        y_res_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test_encoded=y_res_test.replace({'Defaulted': 1, 'Fully Repaid': 0})\n",
    "y_pred_rf_encoded = best_rf.predict_proba(x_res_test_encoded)[:, 0]\n",
    "\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test_encoded, y_pred_rf_encoded)\n",
    "\n",
    "# compute the area under the ROC curve (AUC)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_rf, tpr_rf, color='red', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc_rf)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "feature_importances = best_rf.feature_importances_\n",
    "feature_names = x_res_train_encoded.columns  \n",
    "\n",
    "# sort the feature importances in descending order\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "sorted_importances = feature_importances[sorted_indices]\n",
    "sorted_feature_names = feature_names[sorted_indices]\n",
    "\n",
    "# select the top 10 features\n",
    "top_n = 10\n",
    "top_indices = sorted_indices[:top_n]\n",
    "top_importances = sorted_importances[:top_n]\n",
    "top_feature_names = sorted_feature_names[:top_n]\n",
    "\n",
    "# plot the top 10 feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_importances)), top_importances, tick_label=top_feature_names)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd13cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all ROC curve together\n",
    "plt.figure()\n",
    "plt.plot(fpr_dt, tpr_dt, color='darkorange', lw=2, label='Decision Tree (AUC = %0.2f)' % roc_auc_dt)\n",
    "plt.plot(fpr_rf, tpr_rf, color='red', lw=2, label='Random Forest (AUC = %0.2f)' % roc_auc_rf)\n",
    "plt.plot(fpr_boosted, tpr_boosted, color='blue', lw=2, label='Boosted Tree (AUC = %0.2f)' % roc_auc_boosted)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041670d9",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa36e7",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y label\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "# change to dummy variable\n",
    "categorical_cols_class = x.select_dtypes(include=['object']).columns\n",
    "categorical_cols_class=categorical_cols_class.drop(['SELLER','STATE'])\n",
    "categorical_label = [\"SELLER\", \"STATE\"]\n",
    "x_encoded = pd.get_dummies(x, columns=categorical_cols_class)\n",
    "x_encoded['SELLER']=label_encoder.fit_transform(x_encoded['SELLER'])\n",
    "x_encoded['STATE']=label_encoder.fit_transform(x_encoded['STATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a68c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_encoded,y_encoded, test_size=0.3, random_state=42)\n",
    "df_sf_train=x_train\n",
    "df_sf_train['loan_status']=y_train\n",
    "\n",
    "## divide two unbalancing data set\n",
    "df_sf_train_fully_repaid=df_sf_train[df_sf_train['loan_status']== 1]\n",
    "df_sf_train_default=df_sf_train[df_sf_train['loan_status']== 0]\n",
    "\n",
    "# resample data and scale\n",
    "df_sf_reduced_fully_repaid=df_sf_train_fully_repaid.sample(n=300000)\n",
    "df_sf_train = pd.concat([df_sf_reduced_fully_repaid, df_sf_train_default], axis=0, ignore_index=True)\n",
    "y_train=df_sf_train[\"loan_status\"]\n",
    "x_train=df_sf_train.drop(\"loan_status\", axis=1)\n",
    "smote = SMOTE()\n",
    "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "x_resampled_scaled = scaler.fit_transform(x_resampled)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470309c4",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cross validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "## using Logistic regression for class imbalance\n",
    "model = LogisticRegression(max_iter=10000, solver='liblinear') #class_weight='balanced'\n",
    "grid_search_cv = GridSearchCV(estimator = model, param_grid = params, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True, verbose = 1)            \n",
    "grid_search_cv.fit(x_resampled_scaled, y_resampled)\n",
    "\n",
    "## reviewing the results\n",
    "cv_results = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec36614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result check\n",
    "best_logistic_regression_model = grid_search_cv.best_estimator_\n",
    "coefficients = abs(best_logistic_regression_model.coef_)\n",
    "feature_names = x_train.columns\n",
    "feature_coefficients = dict(zip(feature_names, coefficients[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46373387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot importance features\n",
    "feature_coefficients = list(zip(feature_names, coefficients[0]))\n",
    "\n",
    "sorted_coefficients = sorted(feature_coefficients, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "top_10_coefficients = sorted_coefficients[:10]\n",
    "\n",
    "top_10_variable_names = [item[0] for item in top_10_coefficients]\n",
    "top_10_variable_coefficients = [item[1] for item in top_10_coefficients]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10_variable_names, top_10_variable_coefficients, color='skyblue')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 10 Features by Coefficient Magnitude')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = grid_search_cv.predict(x_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Default', 'Fully-repaid'], yticklabels=['Default', 'Fully-repaid'])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195219e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_proba = grid_search_cv.predict_proba(x_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554f331",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3889bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "x_res_test_encoded_scaled = scale(x_res_test_encoded)\n",
    "x_res_train_encoded_scaled = scale(x_res_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a923f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the initial SVM and plot Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf_svm = SVC(random_state=42, probability=True)\n",
    "clf_svm.fit(x_res_train_encoded_scaled, y_res_train)\n",
    "\n",
    "#calculate overall accuracy\n",
    "y_pred = clf_svm.predict(x_res_test_encoded_scaled)\n",
    "accuracy = accuracy_score(y_res_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "\n",
    "class_names = ['Did Not Default', 'Defaulted']\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        clf_svm,\n",
    "        x_res_test_encoded_scaled,\n",
    "        y_res_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top 10 features\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "\n",
    "# calculate permutation importance with reduced repeats and parallelization\n",
    "perm_importance = permutation_importance(clf_svm, \n",
    "                                         x_res_test_encoded_scaled, \n",
    "                                         y_res_test, \n",
    "                                         n_repeats=2, \n",
    "                                         random_state=42,\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "# get the feature importances and feature indices\n",
    "feature_importances = perm_importance.importances_mean\n",
    "feature_indices = np.arange(len(feature_importances))\n",
    "\n",
    "# sort the feature importances and indices in descending order\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# print the top features\n",
    "top_features = 10  # Choose the number of top features to display\n",
    "for i in range(top_features):\n",
    "    print(f\"Feature {sorted_indices[i]}: Importance {feature_importances[sorted_indices[i]]}\")\n",
    "\n",
    "# get the column names of x_res_train_encoded\n",
    "feature_names = x_res_train_encoded.columns\n",
    "# get the top 10 feature names\n",
    "top_feature_names = feature_names[sorted_indices[:top_features]]\n",
    "\n",
    "# print the top feature names and their importances\n",
    "for i in range(top_features):\n",
    "    print(f\"{top_feature_names[i]}: {feature_importances[sorted_indices[i]]}\")\n",
    "\n",
    "# plot the top features with their names\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(top_features), feature_importances[sorted_indices[:top_features]], color='skyblue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Permutation Importance')\n",
    "plt.title('Top 10 Features by Permutation Importance')\n",
    "plt.xticks(range(top_features), feature_names[sorted_indices[:top_features]], rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afec8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sssuming you have already trained your model and obtained predicted probabilities\n",
    "y_pred_proba = clf_svm.predict_proba(x_res_test_encoded_scaled)[:, 1]\n",
    "\n",
    "# compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_res_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize model with hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "param_grid = {'C':[100], #[0.5,0.1,1,10,100,1000]\n",
    "              'gamma':[1,'scale'],#['scale', 1,0.1, 0.01,0.001,0.0001]\n",
    "              'kernel':['rbf'],\n",
    "              'probability': [True]}\n",
    "\n",
    "optimal_params = GridSearchCV(SVC(), param_grid, cv = 5, scoring='accuracy', verbose=3)\n",
    "optimal_params.fit(x_res_train_encoded_scaled, y_res_train)\n",
    "\n",
    "## see \"best\" parameters\n",
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## refit model with optimal hyperparameters\n",
    "#grid_predictions = optimal_params.predict(x_res_test_encoded.values)\n",
    "grid_predictions = optimal_params.predict(x_res_test_encoded.values)\n",
    "#clf_svm = SVC(random_state = 42, C=1, gamma=0.1, kernel='poly')\n",
    "#clf_svm.fit(x_res_train_encoded_scaled, y_res_train)\n",
    "\n",
    "## calculate overall accuracy\n",
    "#y_pred = clf_svm.predict(x_res_test_encoded_scaled)\n",
    "accuracy = accuracy_score(y_res_test, grid_predictions)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "\n",
    "## plot confusion matrix\n",
    "cm = confusion_matrix(y_res_test, grid_predictions)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad084322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# calculate predicted probabilities for the positive class\n",
    "y_pred_proba = optimal_params.predict_proba(x_res_test_encoded_scaled)[:, 1]\n",
    "\n",
    "# calculate fpr and tpr for the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_res_test, y_pred_proba)\n",
    "\n",
    "# calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_res_test, y_pred_proba)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying PCA to reduce dimensioanlity\n",
    "from sklearn.decomposition import PCA\n",
    "# reducing dimensionality within the data\n",
    "pca = PCA()\n",
    "x_train_pca = pca.fit_transform(x_res_train_encoded_scaled)\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_*100, decimals=1)\n",
    "labels = [str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "#plot scree plot\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var)\n",
    "plt.tick_params(axis='x', which = 'both', bottom=False, top=False, labelbottom=False)\n",
    "plt.ylabel(\"Explained variance (%)\")\n",
    "plt.xlabel('Principal Components')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3236bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using first 2 PCA\n",
    "train_pc1_coords = x_train_pca[:, 0]\n",
    "train_pc2_coords = x_train_pca[:, 1]\n",
    "\n",
    "pca_train_scaled = scale(np.column_stack((train_pc1_coords, train_pc2_coords)))\n",
    "\n",
    "param_grid = {'C':[100], #[0.01, 0.1, 0.5, 1, 10, 100]\n",
    "              'gamma':[1], #[1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001]\n",
    "              'kernel':['rbf']}\n",
    "optimal_params = GridSearchCV(SVC(), param_grid, cv = 5, scoring='accuracy', verbose=3)\n",
    "\n",
    "optimal_params.fit(pca_train_scaled, y_res_train)\n",
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e99576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCA visualisation\n",
    "clf_svm = SVC(random_state=42, C=100, gamma=1)\n",
    "clf_svm.fit(pca_train_scaled, y_res_train)\n",
    "\n",
    "X_test_pca = pca.transform(x_res_train_encoded_scaled)\n",
    "test_pc1_coords = X_test_pca[:, 0]\n",
    "test_pc2_coords = X_test_pca[:, 1]\n",
    "\n",
    "x_min = test_pc1_coords.min()-1\n",
    "x_max = test_pc1_coords.max()+1\n",
    "y_min = test_pc2_coords.min()-1\n",
    "y_max = test_pc2_coords.max()+1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(start=x_min, stop=x_max, step=0.1),np.arange(start=y_min, stop=y_max, step=0.1) )\n",
    "\n",
    "Z = clf_svm.predict(np.column_stack((xx.ravel(), yy.ravel())))\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# visualizing the data\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.contourf(xx,yy, Z, alpha=0.1)\n",
    "cmap = colors.ListedColormap(['#e41a1c', '#4daf4a'])\n",
    "scatter = ax.scatter(test_pc1_coords, test_pc2_coords, c=y_res_train, cmap=cmap, s=100, edgecolors='k', alpha=0.7)\n",
    "legend = ax.legend(scatter.legend_elements()[0], scatter.legend_elements()[1], loc='upper right')\n",
    "legend.get_texts()[0].set_text('Defaulted')\n",
    "legend.get_texts()[1].set_text('Did not Default')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_title('Visualizing the Decision Boundary Using Principal Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84085147",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078245f1",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ea8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variable encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "x_train_encoded = pd.DataFrame(encoder.fit_transform(x_res_train[categorical_cols]),index=x_res_train.index)\n",
    "x_test_encoded = pd.DataFrame(encoder.transform(x_test[categorical_cols]),index=x_test.index)\n",
    "\n",
    "# y LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_res_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# combine encoded categorical data and numerical data\n",
    "x_train_processed = pd.concat([x_train_encoded, x_res_train[numerical_cols]], axis=1)\n",
    "x_test_processed = pd.concat([x_test_encoded,x_test[numerical_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a0502",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=x_train_processed.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# set model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "model.fit(x_train_processed, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# evaluate model\n",
    "loss,accuracy= model.evaluate(x_test_processed, y_test_encoded)\n",
    "print('Test Accuracy:', accuracy)\n",
    "\n",
    "# convert NN result to be classification\n",
    "y_pred = model.predict(x_test_processed) \n",
    "y_class_pred = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24687e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot confusion matrix\n",
    "class_names = ['Defaulted', 'Fully Repaid']\n",
    "\n",
    "cm = confusion_matrix(np.array(y_test_encoded), y_class_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2d92f",
   "metadata": {},
   "source": [
    "### Compare ROC curves of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log=pd.read_csv(\"C:/Users/12095/Desktop/Big Data I/Presentation/output_prob.csv\")\n",
    "pred_log.reset_index(drop=True)\n",
    "pred_log=pred_log['0']\n",
    "pred_log=1-np.array(pred_log)\n",
    "\n",
    "test_log=pd.read_csv(\"C:/Users/12095/Desktop/Big Data I/Presentation/test_log.csv\")\n",
    "test_log.reset_index(drop=True)\n",
    "test_log=test_log['0']\n",
    "test_log=np.array(test_log)\n",
    "test_log=np.where(test_log == 1, 0, 1)\n",
    "\n",
    "pred_svm=pd.read_csv(\"C:/Users/12095/Desktop/Big Data I/Presentation/pred_SVM(3).csv\")\n",
    "pred_svm=pred_svm['0']\n",
    "pred_svm=np.array(pred_svm)\n",
    "\n",
    "test_svm=pd.read_csv(\"C:/Users/12095/Desktop/Big Data I/Presentation/test_SVM(3).csv\")\n",
    "test_svm=test_svm['loan_status']\n",
    "test_svm=np.array(test_svm)\n",
    "\n",
    "pred_tree=pd.read_csv(\"C:/Users/12095/Desktop/Big Data I/Presentation/y_pred_proba_boosted.csv\")\n",
    "pred_tree.reset_index(drop=True)\n",
    "pred_tree=pred_tree['0']\n",
    "pred_tree=np.array(pred_tree)\n",
    "\n",
    "test_tree=pd.read_csv(\"C:/Users/12095/Desktop/Big Data I/Presentation/test_tree.csv\")\n",
    "test_tree.reset_index(drop=True)\n",
    "test_tree=test_tree['loan_status']\n",
    "test_tree=np.array(test_tree)\n",
    "\n",
    "test_nn=np.where(y_test_encoded == 1, 0, 1)\n",
    "pred_nn=np.where(y_class_pred.flatten() == 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ROC value\n",
    "fpr_nn, tpr_nn, thresholds_nn = roc_curve(test_nn, (1-y_pred))\n",
    "fpr_svm, tpr_svm, thresholds_svm = roc_curve(test_svm, pred_svm)\n",
    "fpr_log, tpr_log, thresholds_log = roc_curve(test_log, pred_log)\n",
    "fpr_tree, tpr_tree, thresholds_tree = roc_curve(test_tree, pred_tree)\n",
    "# calculate AUC value\n",
    "roc_auc_nn = auc(fpr_nn, tpr_nn)\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "roc_auc_log = auc(fpr_log, tpr_log)\n",
    "roc_auc_tree = auc(fpr_tree, tpr_tree)\n",
    "\n",
    "# plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_nn, tpr_nn, color='darkorange', lw=2, label='Nerual Network (AUC = %0.2f)' % roc_auc_nn)\n",
    "plt.plot(fpr_svm, tpr_svm, color='red', lw=2, label='Support Vector Machine (AUC = %0.2f)' % roc_auc_svm)\n",
    "plt.plot(fpr_log, tpr_log, color='blue', lw=2, label='Logistic (AUC = %0.2f)' % roc_auc_log)\n",
    "plt.plot(fpr_tree, tpr_tree, color='green', lw=2, label='Boosted Tree (AUC = %0.2f)' % roc_auc_tree)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
